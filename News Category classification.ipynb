{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb1d3b37-abf2-4d01-8fe0-7f494a3db630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "SEED=42\n",
    "torch.manual_seed(SEED)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0240eab-cb1f-4b7a-93ab-b220f69edbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Participants_Data_News_category/Data_Train.xlsx')\n",
    "df = df.sample(frac = 1, random_state=42, axis = 0)\n",
    "df.SECTION = df.SECTION.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_count = np.min(df.SECTION.value_counts())\n",
    "# min_count\n",
    "# df2 = pd.DataFrame(columns=['STORY', 'SECTION'])\n",
    "# texts = []\n",
    "# classes = []\n",
    "# for cat in range(4):\n",
    "#     temp_idxs = df.index[df.SECTION==cat][:min_count]\n",
    "#     frames = [df.iloc[temp_idxs, :], df2]\n",
    "#     df2 = pd.concat(frames, sort=False)\n",
    "\n",
    "# len(df2) / min_count\n",
    "# df2.reset_index(drop = True, inplace=True)\n",
    "# df2.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3157d2f-fcad-4047-800c-f0cc2b5a05af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    \"\"\"Class to build vocabulary for mapping\"\"\"\n",
    "    def __init__(self, token_to_idx = None, add_unk = True, unk_token = \"<UNK>\", mask_token=\"<MASK>\", begin_seq_token=\"<BEGIN>\",end_seq_token=\"<END>\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_to_idx: Initialize token to idx dictionary.\n",
    "            add_unk: Whether to include the unknown token in the vocabulary\n",
    "            unk_token: How the unknown token is represented in the vocabulary\n",
    "        \"\"\"\n",
    "        \n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "            \n",
    "        self._token_to_idx = token_to_idx\n",
    "        \n",
    "        self._idx_to_token = {idx:token \n",
    "                             for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "#         self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_seq_token = begin_seq_token\n",
    "        self._end_seq_token = end_seq_token\n",
    "\n",
    "#         self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)\n",
    "        self.begin_seq_index = self.add_token(self._begin_seq_token)\n",
    "        self.end_seq_index = self.add_token(self._end_seq_token)\n",
    "        \n",
    "        self._add_unk = add_unk\n",
    "        \n",
    "    def from_serializable(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            A dictionary that can be serialized\n",
    "        \"\"\"\n",
    "\n",
    "        return cls(**contents)\n",
    "        \n",
    "    def add_token(self, token):\n",
    "        \"\"\" Update mapping dictionaries given the token\n",
    "        Args:\n",
    "            token (str): Token to add to the vocabulary\n",
    "        Returns:\n",
    "            index (int): The index corresponding to the token          \n",
    "        \"\"\"\n",
    "\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "\n",
    "        return index\n",
    "        \n",
    "    def lookup_token(self, token):\n",
    "        \"\"\" Retrieves the index associated with the token\n",
    "            or the UNK index if the token isn't present in the vocabulary\n",
    "\n",
    "        Args:\n",
    "            token (str): The token for which the index has to be retrieved\n",
    "        Returns:\n",
    "            index (int): The index associated with the token in the dictionary\n",
    "\n",
    "        Note: \n",
    "            'UNK Index' has to be >=0 for the UNK functionality\n",
    "        \"\"\"\n",
    "\n",
    "        if self._add_unk:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx.get(token)\n",
    "\n",
    "    def lookup_index(self, index):\n",
    "        \"\"\"Retrieve the token associated with the index\n",
    "        Args:\n",
    "            index (int): The index to look up\n",
    "        Returns:\n",
    "            token (str): The token associated with the index\n",
    "        Raises:\n",
    "            KeyError: if the index is not in the vocabulary\n",
    "        \"\"\"\n",
    "\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index %d is not in the vocabulary\" % index)\n",
    "        else:\n",
    "            return self._idx_to_token[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the vocabulary\n",
    "        \"\"\"\n",
    "        return len(self._token_to_idx)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class News_Category(Dataset):\n",
    "    def __init__(self, df, nlp, vocab):\n",
    "        \"\"\"Initializing\n",
    "        Args:\n",
    "            df (Pandas DataFrame): Dataframe consisting of tweets and labels\n",
    "            nlp (spacy object): For preprocessing\n",
    "            vocab (Vocabulary Object): To vectorize the tweets\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.nlp = nlp\n",
    "        self.vocab = vocab\n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, self.df.STORY)) + 1\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "          \n",
    "        tweet =  self.df.STORY.iloc[idx]\n",
    "        \n",
    "        label = self.df.SECTION.iloc[idx]\n",
    "        return {'tweet':torch.LongTensor(self.preprocess(tweet)), 'label':label}\n",
    "    \n",
    "    def preprocess(self, sent):\n",
    "        \n",
    "        #Preprocessing and tokenizing\n",
    "        text = sent\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"what's\", \"what is \", text)\n",
    "        text = re.sub(r\"\\'s\", \" \", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "        text = re.sub(r\"can't\", \"can not \", text)\n",
    "        text = re.sub(r\"n't\", \" not \", text)\n",
    "        text = re.sub(r\"i'm\", \"i am \", text)\n",
    "        text = re.sub(r\"\\'re\", \" are \", text)\n",
    "        text = re.sub(r\"\\'d\", \" would \", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "        text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "        text = re.sub('\\W', ' ', text)\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        text = text.strip(' ')\n",
    "        text = re.sub('[^a-zA-Z]',' ',text)\n",
    "        text=text.lower()\n",
    "        sent = text\n",
    "        sent =  \" \".join(sent.split())\n",
    "        sent = [token.lemma_ for token in self.nlp(sent) if token.text not in STOP_WORDS]\n",
    "        sent = self.vectorize(sent)\n",
    "        return sent\n",
    "    \n",
    "    def vectorize(self, sent):\n",
    "        \"\"\"Converts raw text to numeric vectors using the vocabulary\n",
    "        Args:\n",
    "            sent (str): The tweet to be vectorized\n",
    "        Returns:\n",
    "            vector (list): The vector associated with the tweet\n",
    "        \"\"\"\n",
    "        vector = [self.vocab.begin_seq_index]\n",
    "#         vector = []\n",
    "        for token in sent:\n",
    "            vector.append(vocab.lookup_token(token))\n",
    "        vector.append(self.vocab.end_seq_index)\n",
    "            \n",
    "        return vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary(token_to_idx=None, add_unk=True)\n",
    "nlp = spacy.load(name='en_core_web_sm')\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)\n",
    "    text=text.lower()\n",
    "    text = \" \".join(text.split())\n",
    "    text = [token.lemma_ for token in nlp(text) if token.text not in STOP_WORDS]\n",
    "    text = [w for w in text if len(w)>1]\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = df.STORY.apply(clean)\n",
    "text = []\n",
    "for i in range(len(cleaned_tweets)):\n",
    "    for word in cleaned_tweets[i]:\n",
    "        text.append(word)\n",
    "len(text)\n",
    "from collections import Counter\n",
    "count_dict = Counter(text).most_common(len(set(text))-500)\n",
    "for tup in count_dict:\n",
    "    vocab.add_token(tup[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = News_Category(df,nlp, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(filepath):\n",
    "    \"\"\"Loads the glove embeddings\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): path to the glove embeddings file\n",
    "    Return:\n",
    "        word_to_index (dict): Mappings from word to index\n",
    "        embeddings (np.array): Embeddings of the words in the vocabulary\n",
    "    \"\"\"\n",
    "    word_to_index = {}\n",
    "    embeddings = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as fp:\n",
    "        for index, line in enumerate(fp):\n",
    "            line = line.split(\" \")\n",
    "            word_to_index[line[0]] = index\n",
    "            embedding_i = np.array([float(val) for val in line[1:]])\n",
    "            embeddings.append(embedding_i)\n",
    "    \n",
    "    return word_to_index, np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_matrix(filepath, words):\n",
    "    \"\"\"Create embedding matrix for a specific set of words\n",
    "    Args:\n",
    "        word_to_index (dict) : mapping of word to index\n",
    "        embeddings (list): embeddings of words\n",
    "        words (list): List of words in the dictionary\n",
    "    Returns:\n",
    "        final_embeddings (np..array) : embedding matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    word_to_idx, embeddings = load_glove(filepath)\n",
    "    embedding_size = embeddings.shape[1]\n",
    "    final_embeddings = np.zeros((len(words), embedding_size))\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if word in word_to_idx:\n",
    "            final_embeddings[i, :] = embeddings[word_to_idx[word]]\n",
    "        else:\n",
    "            embedding_i = torch.zeros(embedding_size)\n",
    "            final_embeddings[i, :] = embedding_i\n",
    "            \n",
    "    return final_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for idx in range(0, vocab.__len__()):\n",
    "    words.append(vocab.lookup_index(idx))\n",
    "embs = make_embedding_matrix(r\"C:\\Users\\win10\\Documents\\glove.6B\\glove.6B.300d.txt\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([    1, 21507,  4780, 10259, 22374, 16099, 13212, 10903, 10034, 10188,\n",
       "          1128, 23584,  6083, 17023, 22395,  5363, 14999, 22649,   831,  2676,\n",
       "         22649,  7010, 11023,  6185,  6810, 22738,  6083,     0, 12490,  3440,\n",
       "         17486,  7766, 14999,  3392, 10754, 18956, 12846,  8133, 22738,  1128,\n",
       "         23584,  2519, 13212,  4847,     2]),\n",
       " 0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = random.randint(0,4200)\n",
    "print(i)\n",
    "data[i]['tweet'], data[i]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMClassifier(nn.Module):\n",
    "#     def __init__(self, embedding_dim, hidden_dim, label_size, batch_size, embedding_weights, num_layers = 1,bidirectional = False):\n",
    "#         super(LSTMClassifier, self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.batch_size = batch_size\n",
    "#         self.embedding_dim = embedding_dim\n",
    "#         self.word_embeddings = nn.Embedding.from_pretrained(embedding_weights, freeze=False, padding_idx=0)\n",
    "#         self.lstm = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_dim,\n",
    "#                             num_layers = num_layers, bidirectional = bidirectional,batch_first=True)\n",
    "#         if bidirectional:\n",
    "#             self.fc = nn.Linear(hidden_dim*2, label_size)\n",
    "#         else:\n",
    "#             self.fc = nn.Linear(hidden_dim, label_size)\n",
    " \n",
    "#     def forward(self, sentences, train = True):\n",
    "#         embeds = self.word_embeddings(sentences)\n",
    "#         packed_outputs, (hidden,cell) = self.lstm(embeds)\n",
    "#         dense_outputs = self.fc(hidden[1])\n",
    "#         outputs = dense_outputs\n",
    "#         return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, label_size, batch_size, embedding_weights, num_layers = 1,bidirectional = False):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=self.embedding_dim, num_heads=1)\n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(embedding_weights, freeze=False, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(input_size = self.embedding_dim, hidden_size = hidden_dim,\n",
    "                            num_layers = num_layers, bidirectional = bidirectional,batch_first=True)\n",
    "        if bidirectional:\n",
    "            self.fc = nn.Linear(hidden_dim*2, label_size)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim, label_size)\n",
    " \n",
    "    def forward(self, sentences, train = True):\n",
    "        embeds = self.word_embeddings(sentences)\n",
    "        embeds = embeds.permute(1,0,2)\n",
    "        attn_output, _ = self.attention(embeds, embeds, embeds)\n",
    "        packed_outputs, (hidden,cell) = self.lstm(attn_output.permute(1,0,2))\n",
    "        dense_outputs = self.fc(hidden[1])\n",
    "        outputs = dense_outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_nn = nn.LSTM(input_size = 100, hidden_size = 100,\n",
    "#                 num_layers = 2, bidirectional = False,batch_first=True)\n",
    "# print(test_nn(torch.rand(32,8,100))[1][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "nlabel = 4\n",
    "num_layers = 2\n",
    "hidden_dim = 512\n",
    "EMBEDDING_DIM = embs.shape[1]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = LSTMClassifier(embedding_dim=EMBEDDING_DIM,hidden_dim=hidden_dim,label_size=nlabel, batch_size=BATCH_SIZE, embedding_weights=torch.from_numpy(embs).float(), num_layers=num_layers)\n",
    "model = model.to(device)\n",
    " \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.8)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    " \n",
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch\n",
    "    \"\"\"\n",
    "    top_pred = preds.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rewrite collate_ FN function, whose input is the sample data of a batch\n",
    "def collate_fn(batch):\n",
    "\t#Because token_ List is a variable length data, so you need to use a list to load the token of the batch_ list\n",
    "    token_lists = [item['tweet'] for item in batch]\n",
    "    #Each label is an int. we take out all the labels in the batch and reassemble them\n",
    "    labels = [item['label'] for item in batch]\n",
    "    #Converting labels to tensor\n",
    "    labels = torch.LongTensor(labels)\n",
    "    return {\n",
    "    'token_list': torch.nn.utils.rnn.pad_sequence(token_lists, batch_first=True),\n",
    "    'label': labels,\n",
    "    }\n",
    "\n",
    "#When using dataloader to load data, pay attention to collate_ The FN parameter passes in an overridden function\n",
    "trainset = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1, 21327, 15011,  ...,     0,     0,     0],\n",
      "        [    1,  9455,  4973,  ...,     0,     0,     0],\n",
      "        [    1, 21214, 13289,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1, 23685,   441,  ...,     0,     0,     0],\n",
      "        [    1,   159, 10999,  ...,     0,     0,     0],\n",
      "        [    1, 19429,  1598,  ...,     0,     0,     0]])\n",
      "tensor([1, 0, 2, 1, 2, 3, 3, 2, 2, 3, 1, 0, 2, 0, 0, 0, 1, 2, 2, 2, 3, 1, 2, 1,\n",
      "        1, 1, 1, 0, 1, 2, 2, 2, 0, 3, 2, 2, 1, 1, 3, 1, 0, 2, 3, 1, 2, 0, 1, 0,\n",
      "        0, 2, 2, 1, 1, 2, 1, 2, 0, 2, 0, 2, 2, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch in trainset:\n",
    "    print(batch['token_list'])\n",
    "    print(batch['label'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:40<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 1 = 0.47069135028868914\n",
      "accuracy on epoch 1 = 0.8333767364422481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:49<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 2 = 0.12602893096239617\n",
      "accuracy on epoch 2 = 0.9631076390544574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:47<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 3 = 0.08178024136771758\n",
      "accuracy on epoch 3 = 0.97734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:27<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 4 = 0.04905979229467145\n",
      "accuracy on epoch 4 = 0.9861979166666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:20<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 5 = 0.04614558935863897\n",
      "accuracy on epoch 5 = 0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:22<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 6 = 0.03525848129259733\n",
      "accuracy on epoch 6 = 0.9896701390544573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:44<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 7 = 0.018339037647335014\n",
      "accuracy on epoch 7 = 0.9947916666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:46<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 8 = 0.01702782964760748\n",
      "accuracy on epoch 8 = 0.9954427083333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:30<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 9 = 0.01573876737966202\n",
      "accuracy on epoch 9 = 0.9954427083333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:32<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 10 = 0.011045540863657758\n",
      "accuracy on epoch 10 = 0.9962239583333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:34<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 11 = 0.010523825896598282\n",
      "accuracy on epoch 11 = 0.9967447916666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 12 = 0.011178847795478456\n",
      "accuracy on epoch 12 = 0.9951388890544574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:40<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 13 = 0.006773110715039365\n",
      "accuracy on epoch 13 = 0.997265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:40<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 14 = 0.005657874824919418\n",
      "accuracy on epoch 14 = 0.9971354166666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:33<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 15 = 0.0057699566335638035\n",
      "accuracy on epoch 15 = 0.9977864583333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:40<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 16 = 0.005201868737534217\n",
      "accuracy on epoch 16 = 0.9973958333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:50<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 17 = 0.004857403583431127\n",
      "accuracy on epoch 17 = 0.997265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:40<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 18 = 0.004576163718153717\n",
      "accuracy on epoch 18 = 0.9975260416666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:38<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 19 = 0.004783821440863297\n",
      "accuracy on epoch 19 = 0.997265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:31<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 20 = 0.0056270947432039975\n",
      "accuracy on epoch 20 = 0.9971354166666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:30<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 21 = 0.005265184736572337\n",
      "accuracy on epoch 21 = 0.9970052083333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:31<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 22 = 0.004242449122360389\n",
      "accuracy on epoch 22 = 0.9985677083333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:30<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 23 = 0.004865084525939286\n",
      "accuracy on epoch 23 = 0.9975260416666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:30<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 24 = 0.004625556626729121\n",
      "accuracy on epoch 24 = 0.9975260416666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [02:30<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 25 = 0.004508763731723775\n",
      "accuracy on epoch 25 = 0.9973958333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epochs=25\n",
    "for epoch in range(epochs):\n",
    "    time.sleep(1)\n",
    "    total_loss = 0.0\n",
    "    total_acc=0.0\n",
    "    for i, batch in enumerate(tqdm(trainset)):\n",
    "        feature, label = batch['token_list'].to(device), batch['label'].to(device)\n",
    "#         batch_length = torch.tensor(33, dtype = torch.int64).unsqueeze(0)\n",
    "        optimizer.zero_grad()\n",
    "        output =  model(feature).squeeze()\n",
    "        loss = loss_function(output, label)\n",
    "        acc=categorical_accuracy(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc.item() \n",
    "        \n",
    "    scheduler.step()    \n",
    "    print(f\"loss on epoch {epoch+1} = {total_loss/len(trainset)}\")\n",
    "    print(f\"accuracy on epoch {epoch+1} = {total_acc/len(trainset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_excel('Participants_Data_News_category/Sample_submission.xlsx')\n",
    "test_set = pd.read_excel('Participants_Data_News_category\\Data_Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, text, min_len = 4):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    text = re.sub('[^a-zA-Z]',' ',text)\n",
    "    text=text.lower()\n",
    "    text = \" \".join(text.split())\n",
    "    text = [token.lemma_ for token in nlp(text) if token.text not in STOP_WORDS]\n",
    "    vector = []\n",
    "    for token in text:\n",
    "        vector.append(vocab.lookup_token(token))\n",
    "    tensor = torch.LongTensor(vector)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    preds = model(tensor.to(device))\n",
    "    pred_class = preds.argmax(dim = 1)\n",
    "    return pred_class[0]\n",
    "#     print('The sentence is : {}'.format(sent))\n",
    "    # print(f'Predicted class is: {pred_class.item()} = {itol[int(pred_class)]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2748/2748 [01:01<00:00, 44.82it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "for idx in tqdm(test_set.index):\n",
    "    preds.append(predict_class(model,test_set.loc[idx, 'STORY']).item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(preds, columns=['SECTION'])\n",
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9d77b0e9f9ca67815d5a1c7db8aa306d48fa5c14152701c5d5c5c11f6164f8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
